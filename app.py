# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ul0OgnpeO-fgY3OjHufAJS6WE-UlBvSk
"""

import time
import threading
from collections import deque

import av
import cv2
import numpy as np
import requests
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
from ultralytics import YOLO
st.set_page_config(page_title="Accident Detection App", layout="wide")

# ===================== USER CONFIG =====================

# ðŸ‘‰ PUT YOUR TELEGRAM CREDENTIALS HERE
TELEGRAM_BOT_TOKEN = "8576024571:AAGyt5CrHYwR1M5mDsifkbqeDQiB-pNKCdo"
TELEGRAM_CHAT_HOSPITAL = "5261614756"

# Fixed CCTV location (Tamil Nadu)
CAMERA_LAT = 13.049953
CAMERA_LON = 80.282444

# Detection / alert parameters
FLOW_THRESHOLD = 4.0        # motion strength to call it accident
ACCIDENT_COOLDOWN = 15      # seconds between alerts
BUFFER_SECONDS = 5          # length of video clip
EST_FPS = 25                # approximate webcam FPS

# =======================================================

def location_link() -> str:
    return f"https://maps.google.com/?q={CAMERA_LAT},{CAMERA_LON}"


# ---------------- TELEGRAM HELPERS ----------------

def send_telegram_text(text: str):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_HOSPITAL:
        print("Telegram text skipped (token/chat not set).")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        requests.post(url, data={"chat_id": TELEGRAM_CHAT_HOSPITAL, "text": text}, timeout=15)
    except Exception as e:
        print("Telegram text error:", e)


def send_telegram_photo(path: str, caption: str = ""):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_HOSPITAL:
        print("Telegram photo skipped (token/chat not set).")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
    try:
        with open(path, "rb") as img:
            requests.post(
                url,
                data={"chat_id": TELEGRAM_CHAT_HOSPITAL, "caption": caption},
                files={"photo": img},
                timeout=60,
            )
    except Exception as e:
        print("Telegram photo error:", e)


def send_telegram_video(path: str, caption: str = ""):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_HOSPITAL:
        print("Telegram video skipped (token/chat not set).")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendVideo"
    try:
        with open(path, "rb") as vid:
            requests.post(
                url,
                data={"chat_id": TELEGRAM_CHAT_HOSPITAL, "caption": caption},
                files={"video": vid},
                timeout=120,
            )
    except Exception as e:
        print("Telegram video error:", e)


# ---------------- YOLO MODEL ----------------

@st.cache_resource
def load_model():
    m = YOLO("yolov8n.pt")     # fast nano model
    print("YOLOv8n model loaded.")
    return m


yolo_model = load_model()


# ---------------- VIDEO PROCESSOR ----------------

class AccidentProcessor(VideoProcessorBase):
    def __init__(self):
        self.prev_gray_small = None
        self.buffer = deque(maxlen=int(BUFFER_SECONDS * EST_FPS))
        self.last_alert = 0.0
        self.frame_idx = 0

    def _save_clip_and_alert(self, snapshot_bgr: np.ndarray, frames: list[np.ndarray]):
        """Runs in background thread: save snapshot + clip, send Telegram."""
        ts = int(time.time())
        snap_path = f"accident_snapshot_{ts}.jpg"
        clip_path = f"accident_clip_{ts}.mp4"

        # Save snapshot
        try:
            cv2.imwrite(snap_path, snapshot_bgr)
            print("Saved snapshot:", snap_path)
        except Exception as e:
            print("Error saving snapshot:", e)

        # Save clip
        try:
            if frames:
                h, w = frames[0].shape[:2]
                fourcc = cv2.VideoWriter_fourcc(*"mp4v")
                out = cv2.VideoWriter(clip_path, fourcc, EST_FPS, (w, h))
                for f in frames:
                    out.write(f)
                out.release()
                print("Saved clip:", clip_path)
        except Exception as e:
            print("Error saving clip:", e)

        # Prepare caption
        caption = (
            "ðŸš¨ *ACCIDENT ALERT*\n"
            f"Location: {location_link()}\n"
            f"Time: {time.strftime('%Y-%m-%d %H:%M:%S')}"
        )

        # Send Telegram messages
        send_telegram_text(caption)
        send_telegram_photo(snap_path, caption)
        send_telegram_video(clip_path, caption)
        print("ðŸš¨ Accident alert sent to Telegram.")

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        self.buffer.append(img.copy())
        self.frame_idx += 1

        # ----- Global motion (lightweight optical flow on downscaled frames) -----
        small = cv2.resize(img, (320, 240))
        gray_small = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
        motion = 0.0

        if self.prev_gray_small is not None:
            flow = cv2.calcOpticalFlowFarneback(
                self.prev_gray_small,
                gray_small,
                None,
                0.5,
                3,
                15,
                3,
                5,
                1.2,
                0,
            )
            mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])
            motion = float(mag.mean())

        self.prev_gray_small = gray_small

        # ----- YOLO detection (vehicles) -----
        # To reduce load, you can skip some frames. Here we run on every frame.
        results = yolo_model(img, verbose=False, imgsz=640)
        r = results[0]
        boxes = r.boxes.xyxy.cpu().numpy() if r.boxes.xyxy is not None else []
        classes = r.boxes.cls.cpu().numpy().astype(int) if r.boxes.cls is not None else []

        vehicle_boxes = [boxes[i] for i in range(len(boxes)) if classes[i] in (2, 3, 5, 7)]

        # ----- Accident logic -----
        accident = False
        snapshot = None

        if len(vehicle_boxes) >= 1 and motion > FLOW_THRESHOLD:
            accident = True
            snapshot = img.copy()

        now = time.time()
        if accident and (now - self.last_alert) > ACCIDENT_COOLDOWN:
            self.last_alert = now
            # Work on copies so the deque can continue updating
            frames_copy = list(self.buffer)
            snap_copy = snapshot.copy()
            # Run alert logic in background thread so video doesn't freeze
            threading.Thread(
                target=self._save_clip_and_alert,
                args=(snap_copy, frames_copy),
                daemon=True,
            ).start()

        # ----- Draw annotations -----
        annotated = r.plot()  # YOLO draws its own boxes

        # Show motion value
        cv2.putText(
            annotated,
            f"Motion: {motion:.2f}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 0, 255),
            2,
        )

        if accident:
            cv2.putText(
                annotated,
                "ACCIDENT DETECTED!",
                (10, 70),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                (0, 255, 255),
                3,
            )

        return av.VideoFrame.from_ndarray(annotated, format="bgr24")


# ---------------- STREAMLIT UI ----------------

st.markdown(
    """
    <h1 style="text-align:center;">ðŸš¨ Real-Time Accident Detection System</h1>
    <p style="text-align:center;">
    This app uses <b>YOLOv8n</b> + <b>Motion Detection</b> + <b>Telegram Alerts</b> on live CCTV/webcam feed.
    </p>
    """,
    unsafe_allow_html=True,
)

st.sidebar.header("Settings")
st.sidebar.write("â€¢ Make sure camera permission is allowed in your browser.")
st.sidebar.write("â€¢ Press the red Stop button in Streamlit to stop the webcam.")

st.info("Click **Start** below and allow camera access in the browser prompt.")

webrtc_streamer(
    key="accident-detector",
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints={"video": True, "audio": False},
    video_processor_factory=AccidentProcessor,
)